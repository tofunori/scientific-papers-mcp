# Scientific Papers MCP Server

Un serveur Model Context Protocol (MCP) pour la recherche intelligente dans une collection de documents scientifiques sur la glaciologie.

## ğŸ¯ FonctionnalitÃ©s

- **Recherche hybride** : Combinaison de recherche sÃ©mantique (embeddings) et par mots-clÃ©s (BM25)
- **Extraction automatique de mÃ©tadonnÃ©es** : AnnÃ©e, auteurs, tags, instruments, datasets
- **Chunking intelligent** : Respect de la structure des sections markdown
- **Windows natif** : ZÃ©ro dÃ©pendance externe, tout en Python
- **Auto-indexation** : DÃ©tection automatique de nouveaux fichiers

## ğŸš€ Installation

### PrÃ©requis
- Python 3.10 ou supÃ©rieur
- pip ou uv

### Setup

1. Cloner le projet et naviguer au dossier:
```bash
cd scientific-papers-mcp
```

2. Installer les dÃ©pendances:
```bash
pip install -e .
```

Ou avec uv (plus rapide):
```bash
uv pip install -e .
```

3. VÃ©rifier la configuration dans `.env`:
```bash
# Les chemins doivent pointer vers vos rÃ©pertoires
DOCUMENTS_PATH=D:\Github\Revue-de-litterature---Maitrise\Articles
CHROMA_PATH=D:\Claude Code\scientific-papers-mcp\data\chroma
```

## ğŸ“š Utilisation

### Avec Claude Code

1. Ajouter le serveur MCP Ã  Claude Code:
```json
{
  "mcpServers": {
    "scientific-papers": {
      "command": "python",
      "args": ["-m", "src.server"]
    }
  }
}
```

2. Utiliser dans Claude Code:
```
Cherche les articles sur "variabilitÃ© de l'albÃ©do"
```

### Avec des scripts Python

```python
from src.indexing.chroma_client import initialize_chroma
from src.indexing.hybrid_search import HybridSearchEngine

# Initialize
chroma_collection = initialize_chroma("path/to/chroma")
search_engine = HybridSearchEngine(chroma_collection)

# Search
results, scores = search_engine.hybrid_search(
    "glacier albedo feedback",
    top_k=5,
    alpha=0.5  # 50% semantic, 50% keyword
)
```

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ server.py              # Point d'entrÃ©e FastMCP
â”œâ”€â”€ config.py              # Configuration
â”‚
â”œâ”€â”€ extractors/
â”‚   â”œâ”€â”€ metadata_extractor.py    # Extraction mÃ©tadonnÃ©es (regex)
â”‚   â””â”€â”€ patterns.py              # Regex patterns
â”‚
â”œâ”€â”€ indexing/
â”‚   â”œâ”€â”€ chroma_client.py         # Initialisation Chroma
â”‚   â”œâ”€â”€ chunker.py               # Chunking hiÃ©rarchique
â”‚   â””â”€â”€ hybrid_search.py         # Recherche hybride dense+sparse
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ search_tools.py          # MCP tools pour recherche
â”‚   â””â”€â”€ metadata_tools.py        # MCP tools pour mÃ©tadonnÃ©es
â”‚
â””â”€â”€ utils/
    â”œâ”€â”€ logger.py                # Logging
    â””â”€â”€ file_watcher.py          # Auto-indexation
```

## ğŸ“‹ Phases d'implÃ©mentation

- [x] Phase 1: Structure & dÃ©pendances
- [ ] Phase 2: Extraction mÃ©tadonnÃ©es
- [ ] Phase 3: Chroma DB & chunking
- [ ] Phase 4: Recherche hybride
- [ ] Phase 5: MCP tools
- [ ] Phase 6: IntÃ©gration Claude Code
- [ ] Phase 7: Optimisations

## ğŸ“Š Performance estimÃ©e

Pour 50-200 documents:
- Indexation : ~100 ms par document
- Recherche hybride : ~50 ms
- Avec reranking : ~250 ms
- Latence totale acceptable : <500ms

## ğŸ” Exemples de requÃªtes

### Recherche sÃ©mantique
```
"Quels articles parlent de la variabilitÃ© de l'albÃ©do?"
"Impact des feux de forÃªt sur les glaciers"
```

### Recherche de stats
```
"Troupe les valeurs d'albÃ©do entre 0.7 et 0.9"
"Articles avec MODIS 2020-2023"
```

### Filtrage
```
"Articles de Ren et al."
"Ã‰tudes utilisant Sentinel-2"
```

## âš™ï¸ Configuration

Voir `.env` pour les paramÃ¨tres :
- `DOCUMENTS_PATH` : Chemin vers vos documents markdown
- `CHROMA_PATH` : Chemin pour la base de donnÃ©es vectorielle
- `DEFAULT_ALPHA` : Balance recherche sÃ©mantique (1.0) vs keyword (0.0)
- `MAX_CHUNK_SIZE` : Taille maximale des chunks en tokens

## ğŸ¤ Support

Pour les questions ou problÃ¨mes, consultez la documentation MCP builder.

## ğŸ“ Licence

MIT
