# PDF Extraction with LlamaParse

This project uses **LlamaParse** from LlamaIndex for high-quality, cost-effective PDF extraction optimized for scientific papers.

## üéØ Why LlamaParse?

**The perfect solution for scientific papers:**
- ‚úÖ **FREE**: 7,000 pages/week (perfect for research use)
- ‚úÖ **High Quality**: GenAI-native parsing beats traditional OCR
- ‚úÖ **Natural Language Instructions**: Tell it what you want to extract
- ‚úÖ **Superior Extraction**: Tables, equations (LaTeX), figures
- ‚úÖ **Multi-format**: PDF, DOCX, PPTX, ePub support

**For 160 papers (~2,400 pages):**
- **Cost**: $0 (completely free!)
- **Quality**: Excellent for complex scientific documents
- **Speed**: API-based parallel processing

---

## üöÄ Quick Start

### 1. Install Dependencies

```bash
# Install all dependencies (LlamaParse included)
pip install -e .

# Or install with extras
pip install -e ".[all]"
```

### 2. Get API Key

1. Sign up at [LlamaCloud](https://cloud.llamaindex.ai/)
2. Create API key (free tier: 7,000 pages/week)
3. Copy your API key

### 3. Configure `.env`

```bash
# LlamaCloud API Key
LLAMA_CLOUD_API_KEY=your_api_key_here

# Optional: Custom parsing instructions
LLAMAPARSE_PARSING_INSTRUCTION="Extract all text preserving structure. For tables: preserve formatting. For equations: extract as LaTeX."

# Optional: Enable structured metadata extraction
LLAMAEXTRACT_ENABLED=true
```

### 4. Start Indexing

```bash
# Run indexing
python -m src.server
```

---

## ‚öôÔ∏è Configuration Options

All settings in `.env`:

```bash
# Required: API Key
LLAMA_CLOUD_API_KEY=your_api_key_here

# Output format (default: markdown)
LLAMAPARSE_RESULT_TYPE=markdown  # Options: "markdown" or "text"

# Custom parsing instructions (optional, natural language)
LLAMAPARSE_PARSING_INSTRUCTION=""

# Advanced settings
LLAMAPARSE_USE_VENDOR_MULTIMODAL=false  # More expensive multimodal models
LLAMAPARSE_NUM_WORKERS=4                # Parallel workers (1-10)
LLAMAPARSE_MAX_TIMEOUT=2000             # Timeout in seconds
LLAMAPARSE_INVALIDATE_CACHE=false       # Force re-parsing (ignore cache)

# LlamaExtract: Structured metadata (optional)
LLAMAEXTRACT_ENABLED=false              # Enable structured extraction
LLAMAEXTRACT_API_KEY=                   # Optional (uses LLAMA_CLOUD_API_KEY if not set)
LLAMAEXTRACT_SCHEMA_NAME=scientific_paper
```

---

## üìù Natural Language Parsing Instructions

**LlamaParse's unique feature**: Tell it what you want in plain English!

### Default Instruction (Scientific Papers)

```
"Extract all text preserving document structure. "
"For tables: preserve formatting and alignment. "
"For equations: extract as LaTeX when possible. "
"For figures: include captions and descriptions. "
"Maintain section headers and hierarchy."
```

### Custom Instructions Examples

**Methodology-focused:**
```bash
LLAMAPARSE_PARSING_INSTRUCTION="Focus on methodology sections. Extract all experimental procedures, datasets, and evaluation metrics. Preserve code snippets."
```

**Results-focused:**
```bash
LLAMAPARSE_PARSING_INSTRUCTION="Prioritize results sections. Extract all tables with full formatting. Include figure captions and statistical values."
```

**Literature review:**
```bash
LLAMAPARSE_PARSING_INSTRUCTION="Extract introduction and related work. Preserve all citations with author names and years."
```

---

## üé® LlamaExtract: Structured Metadata (Optional)

Enable structured metadata extraction with confidence scores:

```bash
LLAMAEXTRACT_ENABLED=true
```

### Default Schema (Scientific Papers)

Extracts:
- **Basic**: title, authors, year, abstract, keywords, DOI, journal
- **Content**: methodology summary, main findings, conclusions
- **Meta**: datasets used, reference count

### Confidence Scores

Each field includes a confidence score (0.0 to 1.0):

```python
{
  "title": "Deep Learning for Glacier Monitoring",
  "title_confidence": 0.95,  # Very confident
  "methodology": "We used CNN...",
  "methodology_confidence": 0.72,  # Moderate
}
```

**Smart fallback**: Uses extracted data only if confidence ‚â• 50%.

---

## üí° Usage Examples

### Example 1: Basic Extraction

```bash
# .env
LLAMA_CLOUD_API_KEY=llx-abc123...
```

Start indexing - it's that simple!

### Example 2: Custom Instructions

```bash
# .env
LLAMAPARSE_PARSING_INSTRUCTION="Extract methodology and results. Preserve all tables and equations."
```

Focused extraction on what matters to you.

### Example 3: Enhanced Metadata

```bash
# .env
LLAMAEXTRACT_ENABLED=true
```

Get structured metadata:
- Title, authors, abstract
- Methodology summary
- Main findings
- Datasets used

---

## üß™ Testing

### Test Single PDF

```bash
# Test specific PDF
python test_llamaparse.py path/to/paper.pdf

# With custom instructions
python test_llamaparse.py paper.pdf --instruction "Focus on extracting tables and equations"

# Test first PDF from Zotero library
python test_llamaparse.py
```

### Test Full Indexing

```bash
# Index your library
python -m src.server

# Check logs
tail -f logs/scientific_papers.log
```

---

## üìà Performance

**Test setup**: 160 scientific papers, ~2,400 pages

| Metric | Performance |
|--------|-------------|
| **Extraction Time** | ~45-60 minutes (parallel) |
| **Quality** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent |
| **Table Extraction** | ‚úÖ Excellent with formatting |
| **Equation Extraction** | ‚úÖ LaTeX output |
| **Cost** | **$0** (under free tier) |
| **Setup Time** | ~5 minutes |

---

## üêõ Troubleshooting

### "LlamaParse not available"

```bash
pip install llama-parse llama-extract
# Or
pip install -e .
```

### "API key not found"

Check `.env`:
```bash
LLAMA_CLOUD_API_KEY=llx-your-key-here
```

Key must start with `llx-`.

### "Rate limit exceeded"

Free tier: 7,000 pages/week

Solutions:
1. Wait for weekly reset
2. Upgrade to paid tier ($0.003/page)
3. Reduce number of documents

### Slow extraction

Increase workers:
```bash
LLAMAPARSE_NUM_WORKERS=8  # Faster parallel processing
```

### Poor quality

Try custom instructions:
```bash
LLAMAPARSE_PARSING_INSTRUCTION="Focus on scientific content. Extract equations as LaTeX. Preserve table structure exactly."
```

---

## üí∞ Pricing

### Free Tier
- **7,000 pages/week**
- **~1,000 pages/day**
- **Perfect for research use**

### Paid Tier (if needed)
- **$0.003/page**
- **Volume discounts available**
- **No rate limits**

### Your Use Case

**160 papers (~2,400 pages):**
- Initial indexing: **$0**
- Monthly new papers (~150 pages): **$0**

**Recommendation**: Free tier is perfect for research use!

---

## üìö Documentation

- **LlamaCloud**: https://cloud.llamaindex.ai/
- **LlamaParse Docs**: https://docs.cloud.llamaindex.ai/llamaparse
- **LlamaExtract Docs**: https://docs.cloud.llamaindex.ai/llamaextract
- **API Reference**: https://docs.cloud.llamaindex.ai/api-reference

---

## üí¨ FAQ

**Q: Do I need to pay for LlamaParse?**
A: No! Free tier (7,000 pages/week) covers most research use cases.

**Q: What happens if I exceed the free tier?**
A: You can upgrade to paid tier ($0.003/page) or wait for weekly reset.

**Q: Can I use custom parsing instructions?**
A: Yes! Use natural language to tell LlamaParse what to focus on.

**Q: How do I extract structured metadata?**
A: Enable `LLAMAEXTRACT_ENABLED=true` in `.env`.

**Q: What about offline processing?**
A: LlamaParse is API-based, requires internet connection.

---

## üéâ Summary

**Recommended setup for scientific papers:**

```bash
# .env
LLAMA_CLOUD_API_KEY=your_key_here
LLAMAEXTRACT_ENABLED=true
```

**Why this works:**
- ‚úÖ FREE for 160 papers
- ‚úÖ Excellent quality
- ‚úÖ Structured metadata
- ‚úÖ Easy setup
- ‚úÖ Natural language control

**Total cost**: $0/month üéâ

---

**Happy parsing! üìÑ‚ú®**
